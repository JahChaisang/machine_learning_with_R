---
title: "Linear Regression Example"
output:
  html_document: default
  html_notebook: default
---

In this example, we are playing with a diabetes dataset. Here, ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.

```{r}
# Load the diabetes dataset
diabetes <- read.csv("diabetes.csv")
head(diabetes)
```

### Data Preprocessing

Let's standardize all columns that are roughly normal or uniformly distributed.

```{r}
library(caret)
preprocessParams1 <- preProcess(diabetes[c("AGE", "BMI", "BP", "S1", "S2", "S3", "S5", "S6", "Y")], method=c("center", "scale"))
diabetes_trans <- data.frame(predict(preprocessParams1, diabetes))
head(diabetes_trans)
```

Then apply boxcox transformations for those columns that are skewed.

```{r}
preprocessParams2 <- preProcess(diabetes_trans[c("S4")], method=c("BoxCox"))
diabetes_trans <- data.frame(predict(preprocessParams2, diabetes_trans))
head(diabetes_trans)
```

And transform `SEX` to dummy variables.

```{r}
diabetes_trans["SEX"] <- as.numeric(diabetes_trans$SEX == 1)
head(diabetes_trans)
```


### Splitting dataset for cross validation

First, we split the data into two groups: a training set and a test set. To do this, the `sample` function is used.

```{r}
#Preparing Data Sets
trows <- floor(0.65 * nrow(diabetes_trans))
train_idx <- sample(seq_len(nrow(diabetes_trans)), size = trows)

train <- diabetes_trans[train_idx,]
test <- diabetes_trans[-train_idx,]
```

### Data Modeling

Here we create a linear regression model between `Y`, which is our target using all features in the data.


```{r}
hlm <- lm(formula = Y ~ . , data = train)
summary(hlm)
```


Let's examine the factors that are useful for predicting diabetes progression.

```{r}
print(hlm$coefficients)
```

From a quick look, it seems like S1 and S5 (whatever that measure might be) are the most important factors in this model. Let's plot S1 and S5 against our target.

```{r}
plot(diabetes$S1, diabetes$Y)
```

```{r}
plot(diabetes$S5, diabetes$Y)
```

### Cross validate the model on a test set

```{r}
yhat = predict(hlm, newdata=test)
R2 <- 1 - (sum((test$Y-yhat)^2)/sum((test$Y-mean(yhat))^2))
R2
```

### Training regression model using Caret

In Caret package, we can use `trainControl` function to automate a lot of training process. `trainControl` function can be used in conjunction with many training algorithms. 

In `trainControl` function, you can specify how you are going to perform cross validation (how many folds, repeats). You can specify what methods to use for parameter search or parameter selection or performance analysis. Check out the reference link below for complete set of options.

Here we use trainControl to simply performance 3-fold cross validation on our diabetes data.

`trainControl` function is used in conjunction with `train` function. `train` function can receives a formula and a dataframe, or simply x and y variable. Then you can specify method (in this case, a linear model) and `trainControl` output.

```{r}
control <- trainControl(method="cv", number=3)
model <- train(Y~., data=diabetes_trans, method="lm", trControl=control)
model
```


Reference: 
https://www.rdocumentation.org/packages/caret/versions/6.0-76/topics/trainControl
https://www.rdocumentation.org/packages/caret/versions/6.0-76/topics/train
